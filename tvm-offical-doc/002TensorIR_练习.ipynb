{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14oAbaL3iFj0",
        "outputId": "d1ed2519-0c3b-46f4-9639-728c768fc351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-nightly\n",
            "  Downloading https://github.com/mlc-ai/utils/releases/download/v0.9.dev0/mlc_ai_nightly-0.12.dev785%2Bgfc09f562f-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from mlc-ai-nightly) (22.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from mlc-ai-nightly) (2.2.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.9/dist-packages (from mlc-ai-nightly) (6.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from mlc-ai-nightly) (4.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from mlc-ai-nightly) (1.10.1)\n",
            "Requirement already satisfied: numpy<=1.23 in /usr/local/lib/python3.9/dist-packages (from mlc-ai-nightly) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from mlc-ai-nightly) (5.9.4)\n",
            "Installing collected packages: mlc-ai-nightly\n",
            "Successfully installed mlc-ai-nightly-0.12.dev785+gfc09f562f\n"
          ]
        }
      ],
      "source": [
        "!pip install mlc-ai-nightly -f https://mlc.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.如何编写TensorIR"
      ],
      "metadata": {
        "id": "1h1GY6L9itQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm.ir.module import IRModule\n",
        "from tvm.script import tir as T "
      ],
      "metadata": {
        "id": "Z0k72dBfixIg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(16).reshape(4, 4)\n",
        "b = np.arange(16, 0, -1).reshape(4, 4)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7O00HmojDA6",
        "outputId": "6c95a9bd-778e-4d6e-c88e-f508e6eb3b7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]\n",
            " [12 13 14 15]]\n",
            "[[16 15 14 13]\n",
            " [12 11 10  9]\n",
            " [ 8  7  6  5]\n",
            " [ 4  3  2  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_np = a + b\n",
        "c_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ07DQeqjLs2",
        "outputId": "ccc18c35-08f0-4dce-b6ae-43e8e59d05a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "先将高级计算抽象转化为低级Python实现"
      ],
      "metadata": {
        "id": "5BtPi-p6nJc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lnumpy(a: np.ndarray, b: np.ndarray, c:np.ndarray):\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      c[i, j] = a[i, j] + b[i, j]\n",
        "c_lnumpy = np.empty((4, 4), dtype=np.int64)\n",
        "lnumpy(a, b, c_lnumpy)\n",
        "c_lnumpy"
      ],
      "metadata": {
        "id": "gG6x_lhmjOlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb3e5a2-a911-47a5-91d1-0529621361d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "将低级别的numpy 转化为TensorIR"
      ],
      "metadata": {
        "id": "h5rLKTqgreJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer((4, 4), \"int64\"),\n",
        "          B : T.Buffer((4, 4), \"int64\"),\n",
        "          C : T.Buffer((4, 4), \"int64\")):\n",
        "    T.func_attr({\"global_symbol\": \"add\"})\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
        "\n",
        "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
        "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
      ],
      "metadata": {
        "id": "uzqGMooCrBqU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 广播加法"
      ],
      "metadata": {
        "id": "S-LcEl7muCJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(16).reshape(4, 4)\n",
        "b = np.arange(4, 0, -1).reshape(4)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JntRPVvWtpeV",
        "outputId": "c3295094-0425-4e70-ae40-6cf81e2f943c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]\n",
            " [12 13 14 15]]\n",
            "[4 3 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_np = a + b\n",
        "c_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9GF3wmJvI0B",
        "outputId": "36a96502-eded-421f-dae6-e2e5a5a665a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  4,  4,  4],\n",
              "       [ 8,  8,  8,  8],\n",
              "       [12, 12, 12, 12],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "先转化为低级numpy实现"
      ],
      "metadata": {
        "id": "94FVH12CvajU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lnumpy_boargcast_add(a: np.ndarray, b: np.ndarray, c:np.ndarray):\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      c[i, j] = a[i, j] + b[j]\n",
        "c_lnumpy = np.empty((4, 4), dtype=np.int64)\n",
        "lnumpy_boargcast_add(a, b, c_lnumpy)\n",
        "c_lnumpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My2Yc-5OvOQm",
        "outputId": "a3f8a1d7-f7a8-4c94-c40a-47c9b2fde675"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  4,  4,  4],\n",
              "       [ 8,  8,  8,  8],\n",
              "       [12, 12, 12, 12],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "用TensorIR实现"
      ],
      "metadata": {
        "id": "xC6zE7Ui0yfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyAddBoardCast:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer((4, 4), \"int64\"),\n",
        "          B: T.Buffer((4), \"int64\"),\n",
        "          C: T.Buffer((4, 4), \"int64\")):\n",
        "    T.func_attr({\"global_symbol\": \"add\", \"tir.noalias\": True})\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vj]\n",
        "rt_lib = tvm.build(MyAddBoardCast, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
        "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
      ],
      "metadata": {
        "id": "-NwlfK2Yz6hg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 二维卷积"
      ],
      "metadata": {
        "id": "-SPsPext2Qtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, CI, H, W, CO, K = 1, 1, 8, 8, 2, 3\n",
        "OUT_H, OUT_W = H - K + 1, W - K + 1\n",
        "data = np.arange(N*CI*H*W).reshape(N,CI,H,W)\n",
        "weight = np.arange(CO*CI*K*K).reshape(CO, CI, K, K)"
      ],
      "metadata": {
        "id": "YbhC0D5d1vYG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data_torch = torch.Tensor(data)\n",
        "weight_torch = torch.Tensor(weight)\n",
        "conv_torch = torch.nn.functional.conv2d(data_torch, weight_torch)\n",
        "conv_torch = conv_torch.numpy().astype(np.int64)\n",
        "conv_torch.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOEdBtdy3T0W",
        "outputId": "d76dc63d-8d2d-4e8a-bcae-4ad225f5e65e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, 6, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyConv:\n",
        "  @T.prim_func\n",
        "  def conv(DATA_TVM: T.Buffer((N, CI, H, W), \"int64\"),\n",
        "        WEIGHT_TVM: T.Buffer((CO, CI, K, K), \"int64\"),\n",
        "        CONV_TVM: T.Buffer((N, CO, OUT_H, OUT_W), \"int64\")\n",
        "    ):\n",
        "    T.func_attr({\"global_symbol\": \"conv\", \"tir.noalias\": True})\n",
        "    for b, k, i, j, di, dj in T.grid(1, 2,  6, 6, 3, 3):\n",
        "      with T.block(\"CONV_TVM\"):\n",
        "        vb = T.axis.spatial(1, b)\n",
        "        vk = T.axis.spatial(2, k)\n",
        "        vi = T.axis.spatial(6, i)\n",
        "        vj = T.axis.spatial(6, j)\n",
        "        vdi = T.axis.spatial(3, di)\n",
        "        vdj = T.axis.spatial(3, dj)\n",
        "        CONV_TVM[vb,vk,vi,vj] += DATA_TVM[vb,0,vi+vdi,vj+vdj] * WEIGHT_TVM[vk,0,vdi,vdj]    \n",
        "rt_lib = tvm.build(MyConv, target=\"llvm\")\n",
        "data_tvm = tvm.nd.array(data)\n",
        "weight_tvm = tvm.nd.array(weight)\n",
        "conv_tvm = tvm.nd.array(np.zeros((N, CO, OUT_H, OUT_W), dtype=np.int64))\n",
        "rt_lib[\"conv\"](data_tvm, weight_tvm, conv_tvm)\n",
        "np.testing.assert_allclose(conv_tvm.numpy(), conv_torch, rtol=1e-5)"
      ],
      "metadata": {
        "id": "JjTQ8zf03Vgu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.如何变换TensorIR"
      ],
      "metadata": {
        "id": "VawG0IJNwPVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer((4, 4), \"int64\"),\n",
        "          B: T.Buffer((4, 4), \"int64\"),\n",
        "          C: T.Buffer((4, 4), \"int64\")):\n",
        "    T.func_attr({\"global_symbol\": \"add\"})\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
        "\n",
        "sch = tvm.tir.Schedule(MyAdd)\n",
        "block = sch.get_block(\"C\", func_name=\"add\")\n",
        "i, j = sch.get_loops(block)\n",
        "i0, i1 = sch.split(i, factors=[2, 2])\n",
        "sch.parallel(i0)\n",
        "sch.unroll(i1)\n",
        "sch.vectorize(j)\n",
        "IPython.display.Code(sch.mod.script(), language=\"python\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "F1mTfFCrvOcE",
        "outputId": "0ba1f49c-b156-44e7-e885-dc5c48674c6b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "# from tvm.script import ir as I\n",
              "# from tvm.script import tir as T\n",
              "\n",
              "@I.ir_module\n",
              "class Module:\n",
              "    @T.prim_func\n",
              "    def add(A: T.Buffer((4, 4), \"int64\"), B: T.Buffer((4, 4), \"int64\"), C: T.Buffer((4, 4), \"int64\")):\n",
              "        T.func_attr({\"global_symbol\": \"add\"})\n",
              "        # with T.block(\"root\"):\n",
              "        for i_0 in T.parallel(2):\n",
              "            for i_1 in T.unroll(2):\n",
              "                for j in T.vectorized(4):\n",
              "                    with T.block(\"C\"):\n",
              "                        vi = T.axis.spatial(4, i_0 * 2 + i_1)\n",
              "                        vj = T.axis.spatial(4, j)\n",
              "                        T.reads(A[vi, vj], B[vi, vj])\n",
              "                        T.writes(C[vi, vj])\n",
              "                        C[vi, vj] = A[vi, vj] + B[vi, vj]"
            ],
            "text/html": [
              "<style>pre { line-height: 125%; }\n",
              "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
              "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
              "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
              "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
              ".output_html .hll { background-color: #ffffcc }\n",
              ".output_html { background: #f8f8f8; }\n",
              ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
              ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
              ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
              ".output_html .o { color: #666666 } /* Operator */\n",
              ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
              ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
              ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
              ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
              ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
              ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
              ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
              ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
              ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
              ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
              ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
              ".output_html .go { color: #717171 } /* Generic.Output */\n",
              ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
              ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
              ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
              ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
              ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
              ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
              ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
              ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
              ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
              ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
              ".output_html .m { color: #666666 } /* Literal.Number */\n",
              ".output_html .s { color: #BA2121 } /* Literal.String */\n",
              ".output_html .na { color: #687822 } /* Name.Attribute */\n",
              ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
              ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
              ".output_html .no { color: #880000 } /* Name.Constant */\n",
              ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
              ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
              ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
              ".output_html .nf { color: #0000FF } /* Name.Function */\n",
              ".output_html .nl { color: #767600 } /* Name.Label */\n",
              ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
              ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
              ".output_html .nv { color: #19177C } /* Name.Variable */\n",
              ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
              ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
              ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
              ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
              ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
              ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
              ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
              ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
              ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
              ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
              ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
              ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
              ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
              ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
              ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
              ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
              ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
              ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
              ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
              ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
              ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
              ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
              ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
              ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
              ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
              ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
              ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># from tvm.script import ir as I</span>\n",
              "<span class=\"c1\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span class=\"nd\">@I</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
              "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
              "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">add</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">),</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">),</span> <span class=\"n\">C</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">)):</span>\n",
              "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;add&quot;</span><span class=\"p\">})</span>\n",
              "        <span class=\"c1\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span class=\"k\">for</span> <span class=\"n\">i_0</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">parallel</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">):</span>\n",
              "            <span class=\"k\">for</span> <span class=\"n\">i_1</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">unroll</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">):</span>\n",
              "                <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">vectorized</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">):</span>\n",
              "                    <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C&quot;</span><span class=\"p\">):</span>\n",
              "                        <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">i_0</span> <span class=\"o\">*</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"n\">i_1</span><span class=\"p\">)</span>\n",
              "                        <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">)</span>\n",
              "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                        <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
              "</pre></div>\n"
            ],
            "text/latex": "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n\\PY{c+c1}{\\PYZsh{} from tvm.script import ir as I}\n\\PY{c+c1}{\\PYZsh{} from tvm.script import tir as T}\n\n\\PY{n+nd}{@I}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n    \\PY{k}{def} \\PY{n+nf}{add}\\PY{p}{(}\\PY{n}{A}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{C}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{add}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{}):}\n        \\PY{k}{for} \\PY{n}{i\\PYZus{}0} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{parallel}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{:}\n            \\PY{k}{for} \\PY{n}{i\\PYZus{}1} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{unroll}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{:}\n                \\PY{k}{for} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{vectorized}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{C}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                        \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{n}{i\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{2} \\PY{o}{+} \\PY{n}{i\\PYZus{}1}\\PY{p}{)}\n                        \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{n}{j}\\PY{p}{)}\n                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                        \\PY{n}{C}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\n\\end{Verbatim}\n"
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "变换批量矩阵乘法\n",
        "bmm_relu 的numpy写法为"
      ],
      "metadata": {
        "id": "uvnFybh43ueK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lnumpy_mm_relu_v2(A: np.ndarray, B: np.ndarray, C: np.ndarray):\n",
        "  Y = np.empty((16, 288, 288), dtype=\"float32\")\n",
        "  for n in range(16):\n",
        "    for i in range(128):\n",
        "      for j in range(128):\n",
        "        for k in range(128):\n",
        "          if k == 0:\n",
        "            Y[n, i, j] = 0\n",
        "          Y[n, i, j] = Y[n, i, j] + A[n, i, j] * B[n, k, j]\n",
        "  for n in range(16):\n",
        "    for i in range(128):\n",
        "      for j in range(128):\n",
        "        C[n, i, j] = max(Y[n, i, j], 0)\n",
        "        "
      ],
      "metadata": {
        "id": "mkT4ikhyzDmg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyBmmRelu:\n",
        "    @T.prim_func\n",
        "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
        "        T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
        "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
        "        for b, i, j, k in T.grid(16, 128, 128, 128):\n",
        "            with T.block(\"Y\"):\n",
        "                vb, vi, vj, vk = T.axis.remap(\"SSSR\", [b, i, j, k])\n",
        "                with T.init():\n",
        "                    Y[vb, vi, vj] = T.float32(0)\n",
        "                Y[vb, vi, vj] = Y[vb, vi, vj] + A[vb, vi, vk] * B[vb, vk, vj]\n",
        "        for b, i, j in T.grid(16, 128, 128):\n",
        "            with T.block(\"C\"):\n",
        "                vb, vi, vj = T.axis.remap(\"SSS\", [b, i, j])\n",
        "                C[vb, vi, vj] = T.max(Y[vb, vi, vj], T.float32(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRmcITvl5N0d",
        "outputId": "f697ac2e-f860-4bf6-cbee-63d175459b57"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-6ed1a7f2ef6d>:4: DeprecationWarning: T.Buffer[...] is deprecated, use T.Buffer(...) instead\n",
            "  def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
            "<ast>:3: DeprecationWarning: T.Buffer[...] is deprecated, use T.Buffer(...) instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "下面是目标程序，需要将原始程序转化为目标程序"
      ],
      "metadata": {
        "id": "qpzpFFJZA2GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class TargetModule:\n",
        "    @T.prim_func\n",
        "    def bmm_relu(A: T.Buffer((16, 128, 128), \"float32\"), B: T.Buffer((16, 128, 128), \"float32\"), C: T.Buffer((16, 128, 128), \"float32\")) -> None:\n",
        "        T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
        "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
        "        for i0 in T.parallel(16):\n",
        "            for i1, i2_0 in T.grid(128, 16):\n",
        "                for ax0_init in T.vectorized(8):\n",
        "                    with T.block(\"Y_init\"):\n",
        "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                        j = T.axis.spatial(128, i2_0 * 8 + ax0_init)\n",
        "                        Y[n, i, j] = T.float32(0)\n",
        "                for ax1_0 in T.serial(32):\n",
        "                    for ax1_1 in T.unroll(4):\n",
        "                        for ax0 in T.serial(8):\n",
        "                            with T.block(\"Y_update\"):\n",
        "                                n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                                j = T.axis.spatial(128, i2_0 * 8 + ax0)\n",
        "                                k = T.axis.reduce(128, ax1_0 * 4 + ax1_1)\n",
        "                                Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
        "                for i2_1 in T.vectorized(8):\n",
        "                    with T.block(\"C\"):\n",
        "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                        j = T.axis.spatial(128, i2_0 * 8 + i2_1)\n",
        "                        C[n, i, j] = T.max(Y[n, i, j], T.float32(0))"
      ],
      "metadata": {
        "id": "TG5BkYlM6QSu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sch = tvm.tir.Schedule(MyBmmRelu)\n",
        "\n",
        "block_Y = sch.get_block(\"Y\", func_name=\"bmm_relu\")\n",
        "block_C = sch.get_block(\"C\", \"bmm_relu\")\n",
        "\n",
        "b, i, j, k = sch.get_loops(block_Y)\n",
        "i2_0, ax0 = sch.split(j, [16, None])\n",
        "ax1_0, ax1_1 = sch.split(k, [None, 4])\n",
        "sch.reorder(ax1_0, ax1_1, ax0)\n",
        "sch.parallel(b)\n",
        "sch.unroll(ax1_1)\n",
        "sch.reverse_compute_at(block_C, i2_0)\n",
        "sch.decompose_reduction(block_Y, ax1_0)\n",
        "\n",
        "i0, i1, i2_0, i2_1 = sch.get_loops(block_C)\n",
        "sch.vectorize(i2_1)\n",
        "\n",
        "block_Y_init = sch.get_block(\"Y_init\", \"bmm_relu\")\n",
        "\n",
        "b, i, j0, j_1_init = sch.get_loops(block_Y_init)\n",
        "sch.vectorize(j_1_init)"
      ],
      "metadata": {
        "id": "WdCnMGGvCOuu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tvm.ir.assert_structural_equal(sch.mod, TargetModule)\n",
        "print(\"Pass\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJwMIaGSHOPR",
        "outputId": "7334d5d4-e8f7-4df1-8897-905e6df8d014"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before_rt_lib = tvm.build(MyBmmRelu, target=\"llvm\")\n",
        "after_rt_lib = tvm.build(sch.mod, target=\"llvm\")"
      ],
      "metadata": {
        "id": "UrS2nmCFIGu0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "b_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "c_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "after_rt_lib[\"bmm_relu\"](a_tvm, b_tvm, c_tvm)\n",
        "before_timer = before_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
        "print(\"Before transformation\")\n",
        "print(before_timer(a_tvm, b_tvm, c_tvm))\n",
        "\n",
        "f_timer = after_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
        "print(\"After transformation\")\n",
        "print(f_timer(a_tvm, b_tvm, c_tvm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZT9lroBITfx",
        "outputId": "51ce9558-aaa1-44c9-f6e8-bd261be1a321"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before transformation\n",
            "Execution time summary:\n",
            " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
            "  75.5335      75.5335      75.5335      75.5335       0.0000   \n",
            "               \n",
            "After transformation\n",
            "Execution time summary:\n",
            " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
            "  20.1290      20.1290      20.1290      20.1290       0.0000   \n",
            "               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sm4tNvhcJhv1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}